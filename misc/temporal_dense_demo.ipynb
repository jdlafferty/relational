{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `TemporalDense` Demo\n",
    "\n",
    "This notebook demos the `TemporalDense` layer implemented in `temporal_dense.py`.\n",
    "\n",
    "Suppose the input has the shape $(b, t, d)$ where $b$ is the batch dimension, $t$ is the time dimension (i.e.: number of objects), and $d$ is the object dimension.\n",
    "\n",
    "**Hyperparamters:** number of temporal neurons/units $n$, activation function $\\text{Activation}$, whether to use bias, (regularizers, initializers, constraints, etc.)\n",
    "\n",
    "**Trainable parameters:** kernel $W \\in \\mathbb{R}^{t \\times n}$, bias $b \\in \\mathbb{R}^n$\n",
    "\n",
    "The layer performs the following operation:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    x &\\gets \\texttt{einsum(`tn,btd->nd'}, W, \\texttt{inputs)}\\\\\n",
    "    x &\\gets x + b\\\\\n",
    "    x &\\gets \\text{Activation}(x)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "For $v_k = \\texttt{inputs[:, :, k]} \\in \\reals^t$, this is equivalent to \n",
    "\n",
    "$$\n",
    "    v_k \\gets \\text{Activation}(W^\\top v_k + b)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_objects = 2\n",
    "object_dim = 4\n",
    "batch_dim = 1\n",
    "\n",
    "# generate data where features are bernoulli(1/2) \n",
    "data = np.random.randint(0, 2, size=(batch_dim, num_objects, object_dim))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default configuration (`units = None, activation = 'tanh', use_bias=False`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TemporalDense layer\n",
    "# setting units=None => # of temporal neurons = # of objects\n",
    "\n",
    "from temporal_dense import TemporalDense\n",
    "tdense = TemporalDense(units=None, activation='tanh', use_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 4), dtype=float32, numpy=\n",
       "array([[[0.795749  , 0.17126891, 0.85103315, 0.795749  ],\n",
       "        [0.27428737, 0.14592347, 0.4040392 , 0.27428737]]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdense(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, set the TemporalDense layer's kernel to be the defulat one which normalizes by the temporal mean\n",
    "default_kernel = 100*(np.identity(num_objects) - 1/num_objects * np.ones(shape=(num_objects, num_objects)))\n",
    "tdense.kernel.assign(default_kernel);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 4), dtype=float32, numpy=\n",
       "array([[[ 1., -1.,  0.,  1.],\n",
       "        [-1.,  1.,  0., -1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the transformed data is now in the range (-1, 1) as desired\n",
    "tdense(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more general configuration\n",
    "\n",
    "By setting the `units` argument, we can choose the number of \"temporal neurons\". This controls the number of \"objects\" in the output sequence.\n",
    "\n",
    "We can also set the `activation` argument to be any activation function, not necessarily `'tanh'`.\n",
    "\n",
    "Finally, we can add a `bias`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 4), dtype=float32, numpy=\n",
       "array([[[0.79003906, 0.00551224, 0.7955513 , 0.79003906],\n",
       "        [0.        , 0.8442383 , 0.3984375 , 0.        ],\n",
       "        [0.38208008, 0.47436523, 0.8564453 , 0.38208008],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.45507812, 0.        , 0.        ]]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdense = TemporalDense(units=5, activation='relu', use_bias=True)\n",
    "tdense(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the number of objects in the sequence was transformed from 2 to 5. The dimension of the objects is the same since processing is done along the temporal axis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 64-bit ('relml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "feb2622714ee4f3cfc5c273fa3fe6cf9410db521c7e03d7e619a7b4bef5cf3da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
