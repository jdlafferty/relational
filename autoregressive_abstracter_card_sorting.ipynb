{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"source":["# Autoregressive Abstracter: Card Sorting"]},{"cell_type":"markdown","metadata":{},"source":["## Set Up"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:17:38.468460Z","iopub.status.busy":"2023-01-22T00:17:38.468058Z","iopub.status.idle":"2023-01-22T00:19:32.820383Z","shell.execute_reply":"2023-01-22T00:19:32.819071Z","shell.execute_reply.started":"2023-01-22T00:17:38.468429Z"},"trusted":true},"outputs":[],"source":["# %%capture\n","# !git clone https://github.com/jdlafferty/relational.git\n","# %cd relational\n","# !git branch awni-dev\n","# !git checkout awni-dev\n","# !git pull origin awni-dev\n","\n","# !pip install pydealer\n","# !pip install wandb --upgrade\n","# !pip install tensorflow --upgrade"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:32.825823Z","iopub.status.busy":"2023-01-22T00:19:32.825425Z","iopub.status.idle":"2023-01-22T00:19:37.939551Z","shell.execute_reply":"2023-01-22T00:19:37.938258Z","shell.execute_reply.started":"2023-01-22T00:19:32.825776Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-01-22 00:19:32.859273: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-01-22 00:19:33.033461: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:\n","2023-01-22 00:19:33.033521: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","2023-01-22 00:19:34.418320: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:\n","2023-01-22 00:19:34.418585: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:\n","2023-01-22 00:19:34.418603: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}],"source":["import pydealer\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import sklearn.metrics\n","\n","from hand2hand import Cards\n","import utils"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:37.942302Z","iopub.status.busy":"2023-01-22T00:19:37.941072Z","iopub.status.idle":"2023-01-22T00:19:41.286946Z","shell.execute_reply":"2023-01-22T00:19:41.285723Z","shell.execute_reply.started":"2023-01-22T00:19:37.942249Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["env: \"WANDB_NOTEBOOK_NAME\"=\"autoregressive_abstracter_hand_sorting.ipynb\"\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["%env \"WANDB_NOTEBOOK_NAME\" \"autoregressive_abstracter_hand_sorting.ipynb\"\n","\n","import wandb\n","wandb.login(key='283ce55537fabf61a55a960f2788ffcbf12a5b46')"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:41.291134Z","iopub.status.busy":"2023-01-22T00:19:41.290307Z","iopub.status.idle":"2023-01-22T00:19:41.299006Z","shell.execute_reply":"2023-01-22T00:19:41.297858Z","shell.execute_reply.started":"2023-01-22T00:19:41.291090Z"},"trusted":true},"outputs":[],"source":["def create_callbacks(monitor='loss', log_gradients=False, save_model=True, log_weights=True,\n","                     train_ds=None, val_ds=None, ):\n","    callbacks = [\n","#         tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, mode='auto', restore_best_weights=True),\n","#         tf.keras.callbacks.ReduceLROnPlateau( monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto'),\n","        wandb.keras.WandbMetricsLogger(log_freq='epoch'),\n","        wandb.keras,WandbModelCheckpoint(monitor=monitor, mode='auto', save_freq='epoch')\n","#         wandb.keras.WandbCallback(\n","#             monitor=monitor, log_weights=log_weights, log_gradients=log_gradients, save_model=save_model, save_graph=True,\n","#             training_data=train_ds, validation_data=val_ds,\n","#             labels=class_names, predictions=64, compute_flops=True)\n","        ]\n","    return callbacks\n","\n","# metrics = [\n","#         tf.keras.metrics.BinaryAccuracy(name='acc'),\n","#         tf.keras.metrics.Precision(class_id=1, name='precision'),\n","#         tf.keras.metrics.Recall(class_id=1, name='recall'),\n","#         tf.keras.metrics.AUC(curve='ROC', multi_label=True, name='auc')\n","#         ]\n","\n","# loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n","# opt = tf.keras.optimizers.Adam()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:41.301050Z","iopub.status.busy":"2023-01-22T00:19:41.300665Z","iopub.status.idle":"2023-01-22T00:19:41.337052Z","shell.execute_reply":"2023-01-22T00:19:41.336010Z","shell.execute_reply.started":"2023-01-22T00:19:41.301016Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import seq2seq_transformer\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import layers, Model"]},{"cell_type":"markdown","metadata":{},"source":["## [TMP] Re-define `Decoder`\n","\n","The decoder is modified so that it's target sequence input is an arbitrary sequence of vectors rather than a sequence of tokens (so that embedding and adding positional encoding can be done separatly). This makes it more modular and compatible with `SymbolicDecoder` and `EpisodicDecoder`."]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:41.338989Z","iopub.status.busy":"2023-01-22T00:19:41.338409Z","iopub.status.idle":"2023-01-22T00:19:41.349139Z","shell.execute_reply":"2023-01-22T00:19:41.347870Z","shell.execute_reply.started":"2023-01-22T00:19:41.338933Z"},"trusted":true},"outputs":[],"source":["from seq2seq_transformer import AddPositionalEmbedding, DecoderLayer\n","\n","class Decoder(tf.keras.layers.Layer):\n","    def __init__(self, num_layers, num_heads, dff,\n","               dropout_rate=0.1, name='decoder'):\n","        super(Decoder, self).__init__(name=name)\n","\n","        self.num_layers = num_layers\n","        self.num_heads = num_heads\n","        self.dff = dff\n","        self.dropout_rate = dropout_rate\n","\n","    def build(self, input_shape):\n","\n","        _, self.sequence_length, self.d_model = input_shape\n","\n","        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n","\n","        self.dec_layers = [\n","            DecoderLayer(d_model=self.d_model, num_heads=self.num_heads,\n","                         dff=self.dff, dropout_rate=self.dropout_rate)\n","            for _ in range(self.num_layers)]\n","\n","        self.last_attn_scores = None\n","\n","    def call(self, x, encoder_context):\n","\n","        x = self.dropout(x)\n","\n","        for i in range(self.num_layers):\n","            x = self.dec_layers[i](x, encoder_context)\n","\n","#             self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n","\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:41.352089Z","iopub.status.busy":"2023-01-22T00:19:41.351083Z","iopub.status.idle":"2023-01-22T00:19:41.456352Z","shell.execute_reply":"2023-01-22T00:19:41.455299Z","shell.execute_reply.started":"2023-01-22T00:19:41.352040Z"},"trusted":true},"outputs":[],"source":["hand_size = 7\n","\n","deck = Cards()\n","pydeck = pydealer.Deck()\n","pydeck.shuffle()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:41.458588Z","iopub.status.busy":"2023-01-22T00:19:41.458119Z","iopub.status.idle":"2023-01-22T00:19:42.130175Z","shell.execute_reply":"2023-01-22T00:19:42.128980Z","shell.execute_reply.started":"2023-01-22T00:19:41.458540Z"},"trusted":true},"outputs":[],"source":["n = 10000\n","BEGIN_HAND = 52 # token for 'beginning of hand'\n","END_HAND = 53 # token for 'end of hand'\n","\n","hands = np.array(n*(hand_size+2)*[0]).reshape(n, hand_size+2)\n","hands_sorted = np.array(n*(hand_size+2)*[0]).reshape(n, hand_size+2)\n","\n","for i in np.arange(n):\n","    hand = pydeck.deal(hand_size)\n","    if len(hand) < hand_size:\n","        #print('shuffling deck')\n","        pydeck = pydealer.Deck()\n","        pydeck.shuffle()\n","        hand = pydeck.deal(hand_size)\n","    source = list(deck.index_pyhand(hand))\n","    source.insert(0,BEGIN_HAND)\n","    source.append(END_HAND)\n","    hands[i] = np.array(source)\n","    deck.sort_pyhand(hand)\n","    target = list(deck.index_pyhand(hand))\n","    target.insert(0,BEGIN_HAND)\n","    target.append(END_HAND)\n","    hands_sorted[i] = np.array(target)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:42.132840Z","iopub.status.busy":"2023-01-22T00:19:42.131922Z","iopub.status.idle":"2023-01-22T00:19:42.144150Z","shell.execute_reply":"2023-01-22T00:19:42.143014Z","shell.execute_reply.started":"2023-01-22T00:19:42.132791Z"},"trusted":true},"outputs":[],"source":["hands_train, hands_test, sorted_train, sorted_test = train_test_split(hands, hands_sorted, test_size=0.25)\n","\n","source_train = hands_train\n","target_train = sorted_train[:,:-1]\n","labels_train = sorted_train[:,1:]\n","\n","source_test = hands_test\n","target_test = sorted_test[:,:-1]\n","labels_test = sorted_test[:,1:]"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:42.149921Z","iopub.status.busy":"2023-01-22T00:19:42.149555Z","iopub.status.idle":"2023-01-22T00:19:42.157219Z","shell.execute_reply":"2023-01-22T00:19:42.156323Z","shell.execute_reply.started":"2023-01-22T00:19:42.149888Z"},"trusted":true},"outputs":[],"source":["def evaluate_seq2seq_model(model):\n","    n = len(source_test)\n","    output = np.zeros(n*(hand_size+2), dtype=int).reshape(n,hand_size+2)\n","    output[:,0] = BEGIN_HAND\n","    for i in range(hand_size+1):\n","        predictions = model((source_test, output[:, :-1]), training=False)\n","        predictions = predictions[:, i, :]\n","        predicted_id = tf.argmax(predictions, axis=-1)\n","        output[:,i+1] = predicted_id\n","\n","    acc = (np.sum(output[:,1:] == labels_test))/np.prod(labels_test.shape)\n","    print('per-card accuracy: %.2f%%' % (100*acc))\n","    \n","    return acc"]},{"cell_type":"markdown","metadata":{},"source":["## Standard Transformer"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:42.159418Z","iopub.status.busy":"2023-01-22T00:19:42.158612Z","iopub.status.idle":"2023-01-22T00:19:42.168515Z","shell.execute_reply":"2023-01-22T00:19:42.167459Z","shell.execute_reply.started":"2023-01-22T00:19:42.159385Z"},"trusted":true},"outputs":[],"source":["# from seq2seq_transformer import Encoder\n","\n","# inputs = layers.Input(shape=(9,), name='token_input')\n","# target = layers.Input(shape=(8,), name='token_target')\n","\n","# token_embedder = layers.Embedding(54, 128, name='vector_embedding')\n","# pos_embedding_adder_input = AddPositionalEmbedding(name='add_pos_embedding_input')\n","# pos_embedding_adder_target = AddPositionalEmbedding(name='add_pos_embedding_target')\n","# encoder = Encoder(num_layers=3, num_heads=2, dff=64, dropout_rate=0.1, name='transformer_encoder')\n","\n","# decoder = Decoder(num_layers=3, num_heads=2, dff=64, dropout_rate=0.1, name='transformer_decoder')\n","\n","# x = token_embedder(inputs)\n","# x = pos_embedding_adder_input(x)\n","\n","# encoder_context = encoder(x)\n","\n","# target_embedding = token_embedder(target)\n","# target_embedding = pos_embedding_adder_target(target_embedding)\n","\n","# x = decoder(target_embedding, encoder_context)\n","\n","# x = layers.Dense(54)(x)\n","\n","# transformer = Model(inputs=[inputs, target], outputs=x)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:42.170519Z","iopub.status.busy":"2023-01-22T00:19:42.170184Z","iopub.status.idle":"2023-01-22T00:19:42.184907Z","shell.execute_reply":"2023-01-22T00:19:42.183984Z","shell.execute_reply.started":"2023-01-22T00:19:42.170482Z"},"trusted":true},"outputs":[],"source":["from seq2seq_transformer import Encoder\n","\n","class Transformer(tf.keras.Model):\n","    def __init__(self, num_layers, num_heads, dff,\n","            input_vocab_size, target_vocab_size, embedding_dim,\n","            dropout_rate=0.1, name='transformer'):\n","        super().__init__(name=name)\n","        \n","        self.token_embedder = layers.Embedding(input_vocab_size, embedding_dim, name='vector_embedding')\n","        \n","        self.pos_embedding_adder_input = AddPositionalEmbedding(name='add_pos_embedding_input')\n","        self.pos_embedding_adder_target = AddPositionalEmbedding(name='add_pos_embedding_target')\n","\n","        self.encoder = Encoder(num_layers=num_layers, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate, name='encoder')\n","        self.decoder = Decoder(num_layers=num_layers, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate, name='decoder')\n","        self.final_layer = layers.Dense(target_vocab_size, name='final_layer')\n","\n","\n","    def call(self, inputs):\n","        # To use a Keras model with `.fit` you must pass all your inputs in the\n","        # first argument.\n","        source, target  = inputs\n","        \n","        x = self.token_embedder(source)\n","        x = self.pos_embedding_adder_input(x)\n","\n","        encoder_context = self.encoder(x)\n","\n","        target_embedding = self.token_embedder(target)\n","        target_embedding = self.pos_embedding_adder_target(target_embedding)\n","\n","        x = self.decoder(target_embedding, encoder_context)\n","\n","        # Final linear layer output.\n","        logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n","\n","        try:\n","          # Drop the keras mask, so it doesn't scale the losses/metrics.\n","          # b/250038731\n","          del logits._keras_mask\n","        except AttributeError:\n","          pass\n","\n","        # Return the final output and the attention weights.\n","        return logits"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:42.186646Z","iopub.status.busy":"2023-01-22T00:19:42.186273Z","iopub.status.idle":"2023-01-22T00:19:42.260989Z","shell.execute_reply":"2023-01-22T00:19:42.259670Z","shell.execute_reply.started":"2023-01-22T00:19:42.186612Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-01-22 00:19:42.210590: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:\n","2023-01-22 00:19:42.210637: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n","2023-01-22 00:19:42.210676: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (d6744085c45f): /proc/driver/nvidia/version does not exist\n","2023-01-22 00:19:42.211229: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["transformer = Transformer(num_layers=2, num_heads=2, dff=64, \n","    input_vocab_size=54, target_vocab_size=54, embedding_dim=128)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:42.264053Z","iopub.status.busy":"2023-01-22T00:19:42.263175Z","iopub.status.idle":"2023-01-22T00:19:57.966856Z","shell.execute_reply":"2023-01-22T00:19:57.958473Z","shell.execute_reply.started":"2023-01-22T00:19:42.264009Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"transformer\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," vector_embedding (Embedding  multiple                 6912      \n"," )                                                               \n","                                                                 \n"," add_pos_embedding_input (Ad  multiple                 0         \n"," dPositionalEmbedding)                                           \n","                                                                 \n"," add_pos_embedding_target (A  multiple                 0         \n"," ddPositionalEmbedding)                                          \n","                                                                 \n"," encoder (Encoder)           multiple                  298112    \n","                                                                 \n"," decoder (Decoder)           multiple                  562560    \n","                                                                 \n"," final_layer (Dense)         multiple                  6966      \n","                                                                 \n","=================================================================\n","Total params: 874,550\n","Trainable params: 874,550\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["from seq2seq_transformer import masked_loss, masked_accuracy\n","\n","# opt.build(transformer.trainable_variables)\n","transformer.compile(loss=masked_loss, optimizer=tf.keras.optimizers.Adam(), metrics=masked_accuracy)\n","transformer((source_train, target_train))\n","\n","transformer.summary()"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:57.978487Z","iopub.status.busy":"2023-01-22T00:19:57.975916Z","iopub.status.idle":"2023-01-22T00:22:34.015330Z","shell.execute_reply":"2023-01-22T00:22:34.013372Z","shell.execute_reply.started":"2023-01-22T00:19:57.978310Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","118/118 [==============================] - 25s 92ms/step - loss: 1.6558 - masked_accuracy: 0.5691\n","Epoch 2/10\n","118/118 [==============================] - 11s 94ms/step - loss: 0.1822 - masked_accuracy: 0.9515\n","Epoch 3/10\n","118/118 [==============================] - 11s 90ms/step - loss: 0.0901 - masked_accuracy: 0.9758\n","Epoch 4/10\n","118/118 [==============================] - 11s 90ms/step - loss: 0.0586 - masked_accuracy: 0.9843\n","Epoch 5/10\n","118/118 [==============================] - 11s 95ms/step - loss: 0.0460 - masked_accuracy: 0.9876\n","Epoch 6/10\n","118/118 [==============================] - 11s 94ms/step - loss: 0.0373 - masked_accuracy: 0.9903\n","Epoch 7/10\n","118/118 [==============================] - 11s 91ms/step - loss: 0.0355 - masked_accuracy: 0.9904\n","Epoch 8/10\n","118/118 [==============================] - 11s 91ms/step - loss: 0.0347 - masked_accuracy: 0.9907\n","Epoch 9/10\n","118/118 [==============================] - 11s 89ms/step - loss: 0.0231 - masked_accuracy: 0.9940\n","Epoch 10/10\n","118/118 [==============================] - 10s 87ms/step - loss: 0.0234 - masked_accuracy: 0.9938\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7ff0ac027590>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["transformer.fit((source_train, target_train), labels_train, epochs=10, batch_size=64, verbose=1)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:22:34.017664Z","iopub.status.busy":"2023-01-22T00:22:34.017108Z","iopub.status.idle":"2023-01-22T00:22:41.856039Z","shell.execute_reply":"2023-01-22T00:22:41.854674Z","shell.execute_reply.started":"2023-01-22T00:22:34.017618Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["per-card accuracy: 94.40%\n"]}],"source":["evaluate_seq2seq_model(transformer);"]},{"cell_type":"markdown","metadata":{},"source":["## Autoregressive Abstracter with 'Symbolic' Cross-Attention $(Q=A, K=E, V=A)$"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:25:18.852376Z","iopub.status.busy":"2023-01-22T00:25:18.851544Z","iopub.status.idle":"2023-01-22T00:25:18.868511Z","shell.execute_reply":"2023-01-22T00:25:18.867263Z","shell.execute_reply.started":"2023-01-22T00:25:18.852334Z"},"trusted":true},"outputs":[],"source":["from symbolic_decoder import SymbolicDecoder\n","\n","class AutoregressiveSymbolicAbstracter(tf.keras.Model):\n","    def __init__(self, num_layers, num_heads, dff,\n","            input_vocab_size, target_vocab_size, embedding_dim,\n","            dropout_rate=0.1, name='transformer'):\n","        super().__init__(name=name)\n","        \n","        self.token_embedder = layers.Embedding(input_vocab_size, embedding_dim, name='vector_embedding')\n","        \n","        self.pos_embedding_adder_input = AddPositionalEmbedding(name='add_pos_embedding_input')\n","        self.pos_embedding_adder_target = AddPositionalEmbedding(name='add_pos_embedding_target')\n","\n","        self.encoder = Encoder(num_layers=num_layers, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate, name='encoder')\n","        self.abstracter = SymbolicDecoder(num_layers=num_layers, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate, name='abstracter')\n","        self.decoder = Decoder(num_layers=num_layers, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate, name='decoder')\n","        self.final_layer = layers.Dense(target_vocab_size, name='final_layer')\n","\n","\n","    def call(self, inputs):\n","        # To use a Keras model with `.fit` you must pass all your inputs in the\n","        # first argument.\n","        source, target  = inputs\n","        \n","        x = self.token_embedder(source)\n","        x = self.pos_embedding_adder_input(x)\n","\n","        encoder_context = self.encoder(x)\n","\n","        abstracted_context = self.abstracter(encoder_context)\n","        \n","        target_embedding = self.token_embedder(target)\n","        target_embedding = self.pos_embedding_adder_target(target_embedding)\n","\n","        x = self.decoder(target_embedding, abstracted_context)\n","\n","        # Final linear layer output.\n","        logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n","\n","        try:\n","          # Drop the keras mask, so it doesn't scale the losses/metrics.\n","          # b/250038731\n","          del logits._keras_mask\n","        except AttributeError:\n","          pass\n","\n","        # Return the final output and the attention weights.\n","        return logits"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:25:19.673456Z","iopub.status.busy":"2023-01-22T00:25:19.672765Z","iopub.status.idle":"2023-01-22T00:25:19.689969Z","shell.execute_reply":"2023-01-22T00:25:19.688741Z","shell.execute_reply.started":"2023-01-22T00:25:19.673418Z"},"trusted":true},"outputs":[],"source":["autoregressive_symbolic_abstracter = AutoregressiveSymbolicAbstracter(num_layers=2, num_heads=2, dff=64, \n","    input_vocab_size=54, target_vocab_size=54, embedding_dim=128)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:25:22.778048Z","iopub.status.busy":"2023-01-22T00:25:22.777587Z","iopub.status.idle":"2023-01-22T00:25:31.420272Z","shell.execute_reply":"2023-01-22T00:25:31.419027Z","shell.execute_reply.started":"2023-01-22T00:25:22.778010Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"transformer\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," vector_embedding (Embedding  multiple                 6912      \n"," )                                                               \n","                                                                 \n"," add_pos_embedding_input (Ad  multiple                 0         \n"," dPositionalEmbedding)                                           \n","                                                                 \n"," add_pos_embedding_target (A  multiple                 0         \n"," ddPositionalEmbedding)                                          \n","                                                                 \n"," encoder (Encoder)           multiple                  298112    \n","                                                                 \n"," abstracter (SymbolicDecoder  multiple                 563712    \n"," )                                                               \n","                                                                 \n"," decoder (Decoder)           multiple                  562560    \n","                                                                 \n"," final_layer (Dense)         multiple                  6966      \n","                                                                 \n","=================================================================\n","Total params: 1,438,262\n","Trainable params: 1,438,262\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["from seq2seq_transformer import masked_loss, masked_accuracy\n","\n","autoregressive_symbolic_abstracter.compile(loss=masked_loss, optimizer=tf.keras.optimizers.Adam(), metrics=masked_accuracy)\n","autoregressive_symbolic_abstracter((source_train, target_train))\n","\n","autoregressive_symbolic_abstracter.summary()"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:25:31.422874Z","iopub.status.busy":"2023-01-22T00:25:31.422487Z","iopub.status.idle":"2023-01-22T00:29:12.464426Z","shell.execute_reply":"2023-01-22T00:29:12.463132Z","shell.execute_reply.started":"2023-01-22T00:25:31.422837Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","118/118 [==============================] - 37s 155ms/step - loss: 2.7072 - masked_accuracy: 0.2062\n","Epoch 2/10\n","118/118 [==============================] - 17s 143ms/step - loss: 2.4253 - masked_accuracy: 0.2270\n","Epoch 3/10\n","118/118 [==============================] - 16s 139ms/step - loss: 2.3988 - masked_accuracy: 0.2312\n","Epoch 4/10\n","118/118 [==============================] - 17s 141ms/step - loss: 2.3879 - masked_accuracy: 0.2324\n","Epoch 5/10\n","118/118 [==============================] - 17s 140ms/step - loss: 2.3818 - masked_accuracy: 0.2337\n","Epoch 6/10\n","118/118 [==============================] - 17s 144ms/step - loss: 2.3711 - masked_accuracy: 0.2343\n","Epoch 7/10\n","118/118 [==============================] - 17s 142ms/step - loss: 2.3671 - masked_accuracy: 0.2350\n","Epoch 8/10\n","118/118 [==============================] - 17s 147ms/step - loss: 2.3638 - masked_accuracy: 0.2361\n","Epoch 9/10\n","118/118 [==============================] - 17s 146ms/step - loss: 2.3588 - masked_accuracy: 0.2378\n","Epoch 10/10\n","118/118 [==============================] - 17s 141ms/step - loss: 2.3561 - masked_accuracy: 0.2367\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7ff0acda1c50>"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["autoregressive_symbolic_abstracter.fit((source_train, target_train), labels_train, epochs=10, batch_size=64, verbose=1)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:29:12.466381Z","iopub.status.busy":"2023-01-22T00:29:12.466013Z","iopub.status.idle":"2023-01-22T00:29:24.289259Z","shell.execute_reply":"2023-01-22T00:29:24.288227Z","shell.execute_reply.started":"2023-01-22T00:29:12.466349Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["per-card accuracy: 15.85%\n"]}],"source":["evaluate_seq2seq_model(autoregressive_symbolic_abstracter);"]},{"cell_type":"markdown","metadata":{},"source":["## Autoregressive Abstracter with 'Episodic' Cross-Attention $(Q=E, K=E, V=E)$"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:29:24.292067Z","iopub.status.busy":"2023-01-22T00:29:24.291686Z","iopub.status.idle":"2023-01-22T00:29:24.309560Z","shell.execute_reply":"2023-01-22T00:29:24.308461Z","shell.execute_reply.started":"2023-01-22T00:29:24.292034Z"},"trusted":true},"outputs":[],"source":["from seq2seq_transformer import EpisodicDecoder\n","\n","class AutoregressiveEpisodicAbstracter(tf.keras.Model):\n","    def __init__(self, num_layers, num_heads, dff,\n","            input_vocab_size, target_vocab_size, embedding_dim,\n","            dropout_rate=0.1, name='autoregressive_episodic_abstracter'):\n","        super().__init__(name=name)\n","        \n","        self.token_embedder = layers.Embedding(input_vocab_size, embedding_dim, name='vector_embedding')\n","        \n","        self.pos_embedding_adder_input = AddPositionalEmbedding(name='add_pos_embedding_input')\n","        self.pos_embedding_adder_target = AddPositionalEmbedding(name='add_pos_embedding_target')\n","\n","        self.encoder = Encoder(num_layers=num_layers, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate, name='encoder')\n","        self.abstracter = EpisodicDecoder(num_layers=num_layers, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate, name='abstracter')\n","        self.decoder = Decoder(num_layers=num_layers, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate, name='decoder')\n","        self.final_layer = layers.Dense(target_vocab_size, name='final_layer')\n","\n","\n","    def call(self, inputs):\n","        # To use a Keras model with `.fit` you must pass all your inputs in the\n","        # first argument.\n","        source, target  = inputs\n","        \n","        x = self.token_embedder(source)\n","        x = self.pos_embedding_adder_input(x)\n","\n","        encoder_context = self.encoder(x)\n","\n","        abstracted_context = self.abstracter(encoder_context)\n","        \n","        target_embedding = self.token_embedder(target)\n","        target_embedding = self.pos_embedding_adder_target(target_embedding)\n","\n","        x = self.decoder(target_embedding, abstracted_context)\n","\n","        # Final linear layer output.\n","        logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n","\n","        try:\n","          # Drop the keras mask, so it doesn't scale the losses/metrics.\n","          # b/250038731\n","          del logits._keras_mask\n","        except AttributeError:\n","          pass\n","\n","        # Return the final output and the attention weights.\n","        return logits"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:29:24.312995Z","iopub.status.busy":"2023-01-22T00:29:24.311532Z","iopub.status.idle":"2023-01-22T00:29:24.345851Z","shell.execute_reply":"2023-01-22T00:29:24.344765Z","shell.execute_reply.started":"2023-01-22T00:29:24.312927Z"},"trusted":true},"outputs":[],"source":["autoregressive_episodic_abstracter = AutoregressiveEpisodicAbstracter(num_layers=2, num_heads=2, dff=64, \n","    input_vocab_size=54, target_vocab_size=54, embedding_dim=128)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:29:24.348854Z","iopub.status.busy":"2023-01-22T00:29:24.348306Z","iopub.status.idle":"2023-01-22T00:29:32.361459Z","shell.execute_reply":"2023-01-22T00:29:32.360176Z","shell.execute_reply.started":"2023-01-22T00:29:24.348801Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"autoregressive_episodic_abstracter\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," vector_embedding (Embedding  multiple                 6912      \n"," )                                                               \n","                                                                 \n"," add_pos_embedding_input (Ad  multiple                 0         \n"," dPositionalEmbedding)                                           \n","                                                                 \n"," add_pos_embedding_target (A  multiple                 0         \n"," ddPositionalEmbedding)                                          \n","                                                                 \n"," encoder (Encoder)           multiple                  298112    \n","                                                                 \n"," abstracter (EpisodicDecoder  multiple                 563712    \n"," )                                                               \n","                                                                 \n"," decoder (Decoder)           multiple                  562560    \n","                                                                 \n"," final_layer (Dense)         multiple                  6966      \n","                                                                 \n","=================================================================\n","Total params: 1,438,262\n","Trainable params: 1,438,262\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["from seq2seq_transformer import masked_loss, masked_accuracy, CustomSchedule\n","\n","learning_rate = CustomSchedule(d_model=128)\n","autoregressive_episodic_abstracter.compile(\n","    loss=masked_loss, optimizer=tf.keras.optimizers.Adam(learning_rate), metrics=masked_accuracy)\n","autoregressive_episodic_abstracter((source_train, target_train))\n","\n","autoregressive_episodic_abstracter.summary()"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:29:32.363952Z","iopub.status.busy":"2023-01-22T00:29:32.363029Z","iopub.status.idle":"2023-01-22T00:32:43.435679Z","shell.execute_reply":"2023-01-22T00:32:43.434442Z","shell.execute_reply.started":"2023-01-22T00:29:32.363914Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","118/118 [==============================] - 37s 151ms/step - loss: 4.2157 - masked_accuracy: 0.0721\n","Epoch 2/10\n","118/118 [==============================] - 19s 161ms/step - loss: 3.4156 - masked_accuracy: 0.1566\n","Epoch 3/10\n","118/118 [==============================] - 17s 144ms/step - loss: 2.8791 - masked_accuracy: 0.1937\n","Epoch 4/10\n","118/118 [==============================] - 17s 143ms/step - loss: 2.5927 - masked_accuracy: 0.2199\n","Epoch 5/10\n","118/118 [==============================] - 17s 143ms/step - loss: 2.3553 - masked_accuracy: 0.2689\n","Epoch 6/10\n","118/118 [==============================] - 17s 144ms/step - loss: 1.9052 - masked_accuracy: 0.3974\n","Epoch 7/10\n","118/118 [==============================] - 16s 139ms/step - loss: 1.2085 - masked_accuracy: 0.6482\n","Epoch 8/10\n","118/118 [==============================] - 17s 142ms/step - loss: 0.6991 - masked_accuracy: 0.8147\n","Epoch 9/10\n","118/118 [==============================] - 17s 143ms/step - loss: 0.4867 - masked_accuracy: 0.8720\n","Epoch 10/10\n","118/118 [==============================] - 17s 146ms/step - loss: 0.3612 - masked_accuracy: 0.9050\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7ff08d17bc50>"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["autoregressive_episodic_abstracter.fit((source_train, target_train), labels_train,\n","    epochs=10, batch_size=64, verbose=1)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:32:43.438498Z","iopub.status.busy":"2023-01-22T00:32:43.437158Z","iopub.status.idle":"2023-01-22T00:32:54.981523Z","shell.execute_reply":"2023-01-22T00:32:54.980144Z","shell.execute_reply.started":"2023-01-22T00:32:43.438452Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["per-card accuracy: 91.11%\n"]}],"source":["evaluate_seq2seq_model(autoregressive_episodic_abstracter);"]},{"cell_type":"markdown","metadata":{},"source":["## Multi-Abstracter Model\n","\n","$$\\text{Encoder} \\to \\text{Abstracter} \\to \\cdots \\to \\text{Abstracter} \\to \\text{Decoder}$$\n","\n","..."]}],"metadata":{"kernelspec":{"display_name":"math","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11 (default, Aug  6 2021, 09:57:55) [MSC v.1916 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"6344ff784fc1faea94d0e81da8b4b161117140e87b580ec4c92f28840fc25029"}}},"nbformat":4,"nbformat_minor":4}
