\subsection{Universal approximation of relation functions for Abstractors}\label{ssec:universal_approximation}

In this section, we consider the representational power of the Abstractor module for computing functions of relations between a sequence of objects. We defer formal statements and proofs to the appendix. We show that the Abstractor module can approximate arbitrary functions of relations between objects, and that the Abstractor module can be composed to compute higher-order relations. Consider a 1-layer single-head Abstractor acting on a sequence of objects $X = \paren{x_1, \ldots, x_\m} \in \calX^\m$. Let $\sigma_\mathrm{rel}$ be the identity. Then, a 1-layer Abstractor computes abstract states as,
\begin{equation}
    A_i \gets \mathrm{FeedForward}\paren{\sum_{j} \iprod{\phi(x_i)}{\psi(x_j)} s_j}.
\end{equation}

The following result shows that a 1-layer Abstractor can approximate arbitrary functions of each object's relations with the other objects. This result follows from the analysis of function classes of inner products of neural networks in~\citep{TODO:POSTtoARXIV}.
\begin{result}\label{result:abstractor_univ_approximation}
    Let $r: \calX \times \calX \to \reals^{d_r}$ be any relation function. Then, there exists a choice of symbols $s_1, \ldots, s_\m$ and parameters of the feed-forward network such that $A_i$ approximates an arbitrary function of $\paren{r(x_i, x_j)}_{j=1}^\m$.
\end{result}

As discussed in the next section, Abstractor modules can be composed in a broader architecture to compute higher-order relations. The following result states that a composition of $k$ single-layer Abstractors can approximate arbitrary $k$th-order relational functions.

\begin{result}\label{result:abstractor_composition}
    A composition of $k$ single-layer Abstractors is able to compute arbitrary $k$th-order relational functions.
\end{result}

Finally, we present a robustness result which states that relational cross-attention is able to encodes relations robustly via redundancy in the symbols.

\begin{result}\label{result:abstractor_robustness}
    Suppose that symbolic message-passing is used to transform a sequence of $m$ symbols, each of dimension $d$. If a fraction $\epsilon$ of the entries of the transformed symbols are arbitrarily corrupted, the relations can be exactly recovered by a linear program as long as $\sqrt{m/(1-\epsilon)^2d}$ is sufficiently small.
\end{result}

The results of~\citep{model_repair} make the robustness properties precise. We investigate different forms of robustness empirically in the experiments section.
