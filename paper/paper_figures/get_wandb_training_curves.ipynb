{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get W&B data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wandb\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get End-of-training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wandb_project_table(project_name, entity='Awni00', attr_cols=('group', 'name'), config_cols='all', summary_cols='all'):\n",
    "\n",
    "    api = wandb.Api()\n",
    "\n",
    "    runs = api.runs(entity + \"/\" + project_name)\n",
    "\n",
    "    if summary_cols == 'all':\n",
    "        summary_cols = set().union(*tuple(run.summary.keys() for run in runs))\n",
    "\n",
    "    if config_cols == 'all':\n",
    "        config_cols = set().union(*tuple(run.config.keys() for run in runs))\n",
    "\n",
    "    all_cols = list(attr_cols) + list(summary_cols) + list(config_cols)\n",
    "    if len(all_cols) > len(set(all_cols)):\n",
    "        raise ValueError(\"There is overlap in the `config_cols`, `attr_cols`, and `summary_cols`\")\n",
    "\n",
    "    data = {key: [] for key in all_cols}\n",
    "\n",
    "    for run in runs:\n",
    "        for summary_col in summary_cols:\n",
    "            data[summary_col].append(run.summary.get(summary_col, None))\n",
    "\n",
    "        for config_col in config_cols:\n",
    "            data[config_col].append(run.config.get(config_col, None))\n",
    "\n",
    "        for attr_col in attr_cols:\n",
    "            data[attr_col].append(getattr(run, attr_col, None))\n",
    "\n",
    "    runs_df = pd.DataFrame(data)\n",
    "\n",
    "    return runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "projects = [project for project in api.projects('awni00') if 'math-' in project.name and 'old' not in project.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_cols = ['trial']\n",
    "attr_cols = ['group', 'name']\n",
    "\n",
    "project_dfs = []\n",
    "for project in projects:\n",
    "    task_name = project.name.split('-')[1]\n",
    "    project_df = get_wandb_project_table(\n",
    "        project_name=project.name, entity='awni00', attr_cols=attr_cols, config_cols=config_cols, summary_cols='all')\n",
    "    project_df['task'] = task_name\n",
    "    project_dfs.append(project_df)\n",
    "\n",
    "projects_df = pd.concat(project_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_df.reset_index(drop=True).to_csv('figure_data/math_endoftraining_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get training curves from W&B logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_run_histories(project_name, keys, groups=None, entity='Awni00', attr_cols=('group', 'name'), config_cols='all'):\n",
    "    '''gets the log history of all runs in a project'''\n",
    "\n",
    "    def get_run_history(run):\n",
    "        history_scan = run.scan_history(keys=keys)\n",
    "        run_history_data = {key: [] for key in keys}\n",
    "        for row in history_scan:\n",
    "            for key in keys:\n",
    "                run_history_data[key].append(row[key])\n",
    "        return pd.DataFrame(run_history_data)\n",
    "\n",
    "    api = wandb.Api(timeout=60)\n",
    "\n",
    "    runs = api.runs(entity + \"/\" + project_name)\n",
    "    if groups is not None:\n",
    "        runs = [run for run in runs if run.group in groups]\n",
    "\n",
    "    if config_cols == 'all':\n",
    "        config_cols = set().union(*tuple(run.config.keys() for run in runs))\n",
    "\n",
    "    run_history_dfs = []\n",
    "\n",
    "    print(f'fetching run history for {len(runs)} runs in {project_name}')\n",
    "\n",
    "    for run in tqdm(runs):\n",
    "        run_history = get_run_history(run)\n",
    "\n",
    "        for config_col in config_cols:\n",
    "            run_history[config_col] = run.config.get(config_col, None)\n",
    "\n",
    "        for attr_col in attr_cols:\n",
    "            run_history[attr_col] = getattr(run, attr_col, None)\n",
    "\n",
    "        run_history_dfs.append(run_history)\n",
    "\n",
    "    runs_history_df = pd.concat(run_history_dfs, axis=0)\n",
    "\n",
    "    runs_history_df = runs_history_df.reset_index(drop=True)\n",
    "\n",
    "    return runs_history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "projects = [project for project in api.projects('awni00') if 'math-' in project.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Project awni00/math-calculus__differentiate>,\n",
       " <Project awni00/math-algebra__sequence_next_term>,\n",
       " <Project awni00/math-algebra__linear_1d>,\n",
       " <Project awni00/math-polynomials__expand>,\n",
       " <Project awni00/math-polynomials__add>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching run history for 20 runs in math-calculus__differentiate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [31:40<00:00, 95.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching run history for 20 runs in math-algebra__sequence_next_term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "save_dir = 'figure_data/project_run_histories'\n",
    "\n",
    "metrics = ['val_teacher_forcing_accuracy', 'epoch']\n",
    "groups = ['transformer-medium', 'transformer-medium+', 'relational_abstractor-medium',\n",
    "    'symbolretrieving_abstractor_archd-medium', 'symbolretrieving_abstractor_archd-medium']\n",
    "config_cols = ['trial']\n",
    "attr_cols = ['group', 'name']\n",
    "project_dfs = []\n",
    "for project in projects:\n",
    "    task_name = project.name.split('-')[1]\n",
    "    project_df = get_project_run_histories(\n",
    "        project_name=project.name, entity='awni00', keys=metrics, groups=groups, attr_cols=attr_cols, config_cols=config_cols)\n",
    "    project_df.to_csv(f'{save_dir}/run_history_{project.name}.csv')\n",
    "    project_df['task'] = task_name\n",
    "    project_dfs.append(project_df)\n",
    "\n",
    "projects_df = pd.concat(project_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_df.to_csv(f'{save_dir}/project_run_histories.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
