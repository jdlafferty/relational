\section{Introduction}

\texttt{A paragraph on the importance of relations to cognition/intelligence.}

The ability to infer and process relations is at the heart of abstraction and creative thinking. Under one theory of cognitive science, intelligence can be understood through the lens of two categories of cognition---``neocortical'' and ``prefrontal''. Neocortical intelligence is refers to the ability to acquire semantic and procedural knowledge. By contrast, preforntal intelligence refers to the ability to identify novel associations and relations, building abstractions and generalizing to new domains. It is sometimes argued that modern deep learning systems achieve neocortical intelligence through efficient function approximation, but so far have limited prefrontal intelligence.

\texttt{A paragraph on how transformers fit into this theory. the attention mechanisms of transformers enables contextual processing. but they don't support explicit relational reasoning. The emerging literature on relational reasoning shows that the Transformer can be sample-inefficient in learning relational reasoning tasks.}

An example of this is the Transformer architecture \citep{vaswani2017attention}. The transformer is a powerful sequence model with the ability to . A testament to the power and versatility of the Transformer architecture is the fact that it is at the core of the most successful large language models today \citep{gpt3,gpt4,llamma,T5,etc?}. Beyond architectural variations, there is no real competitor to the Transformer in this domain. Recent work has studied the emergent abstraction abilities of large language models based on the Transformer architecture. While large language models shows some ability to complete analogies~\citep{}, this is attained implicitly through processing vast amounts of data.

\texttt{A paragraph introducing our work and our main claims/contributions. relational bottleneck. Abstractor module.}

In this work we propose an extension of the Transformer framework for explicit relational reasoning through a novel module called the \textit{Abstractor}. The Abstractor achieves this enhanced relational reasoning through an inductive bias we call a \textit{relational information bottleneck}. This is an inductive bias which enforces that the representations learned by the Abstractor encode purely relational information which is abstracted away from the attributes of individual objects. At the core of the Abstractor module is a novel variant of attention called \textit{relational cross-attention}.

We empirically evaluate the Abstractor on two sets of tasks. The first set of tasks are based on learning order relations and sorting sequences of randomly-generated objects. This is a sequence-to-sequence relational task, which is so far unexplored in the literature on relational architectures (which has so far focused on discriminative tasks). We compare an Abstractor-based model to a standard transformer and observe dramatic improvements in sample efficiency. The second set of tasks are based on solving mathematical problems. Whereas the sorting tasks are purely relational synthetic tasks, the mathematical problem-solving tasks are more realistic and require a combination of relational reasoning and function approximation. Here too, the Abstractor yields a small but consistent improvement in sample efficiency over a standard transformer. This suggests that explicit relational reasoning is a useful architectural addition to sequence models. We hope that this work marks a step towards the development of machine learning methods and theories that for improved prefrontal intelligence.

\input{related_work}