\section{Introduction}

The ability to infer and process relations and reason in terms 
of analogies lies at the heart of human abilities for abstraction and creative thinking
\citep{snow,holyoak}. This capability is 
largely separate from our ability to acquire semantic and procedural 
knowledge through sensory tasks, such as image and audio processing. Modern 
deep learning systems can often capture this latter type of intelligence 
through efficient function approximation. However, deep learning has 
seen limited success with relational and abstract reasoning, which 
requires identifying novel associations from limited data
and generalizing to new domains. 

Recognizing the importance of this capability,
machine learning research has explored several novel frameworks for relational learning 
\citep{TEM, NTM,episodicControl,shanahanExplicitlyRelationalNeural,esbn,mondal23learned,battaglia,barrett:2018,santoro1}. 
In this paper we propose a framework that casts relational learning in terms of Transformers. 
The success of Transformers lies in combining the function approximation capabilities of deep learning with the use
of attentional mechanisms to support richly context-sensitive processing \citep{transformers,vaswani2017attention,
    kerg2020untangling}. However, it is clear that Transformers are missing core capabilities required for modeling
human thought \citep{mahowald2023dissociating}, including an ability to support analogy and abstraction.
While large language models show a surprising ability to complete some analogies \citep{webb}, this ability
emerges implicitly after processing vast amounts of data.

The Transformer architecture has the ability to model relations between objects implicitly through attention mechanisms. However, we argue in this paper that standard attention produces entangled representations encoding a mixture of relational information and sensory information, resulting in suboptimal sample-efficiency for learning relations. The challenge is to provide ways of binding
domain-specific information to low dimensional, abstract representations 
% that can be used to compute a given function in any setting for which it is relevant, based on limited data.
that can be used in a broader range of sensory domains.

In this work we propose an extension of Transformers that enables explicit relational reasoning through a novel module called the \textit{Abstractor}.
At the core of the Abstractor module is a novel variant of attention called \textit{relational cross-attention}.
% This enables more focused and explicit relational reasoning, separating relational information from extraneous sensory information.
Our approach is motivated by an architectural inductive bias for relational learning we call the
``relational bottleneck," 
which separates relational information from extraneous sensory information, thus enabling more focused and explicit relational reasoning.
% which restricts the flow of information from sensory subsystems to  
% reasoning subsystems to be relational. % To-Do: edit this sentence?
Through the relational cross-attention mechanism, the Abstractor architecture
creates a powerful combination of deep learning and relational learning
% that implements a form of symbolic processing,
enabling abstraction and generalization from limited data.
% Additionally, it enables improved out-of-distribution generalization since the same relations may be present in different domains, even if the underlying sensory information of individual objects is different.

Our empirical evaluation is split into three sections. In the first, we evaluate the Abstractor on simple discriminative relational tasks and compare to existing relational architectures (which so far have focused on discriminative relational tasks).
In the second, we evaluate the Abstractor on a purely relational sequence-to-sequence task---sorting sequences of randomly generated objects. These experiments give us a controlled setting in which to evaluate the Abstractor's ability to model relations. We observe that the Abstractor achieves a dramatic improvement in sample efficiency compared to a standard Transformer.
In the third section, we evaluate the Abstractor on a more realistic task which requires a combination of relational reasoning as well as more general sequence modeling---solving mathematical problems. We observe that the Abstractor yields modest but consistent improvements in performance and sample efficiency over a standard Transformer. This provides evidence that the Abstractor module for relational reasoning is a useful architectural addition to sequence models.

% We empirically evaluate the Abstractor on two sets of tasks. The first set of tasks is based on learning order relations and sorting sequences of objects. This is a sequence-to-sequence relational task, which is so far unexplored in the literature on relational architectures, which had 
% previously focused on discriminative tasks. We compare an Abstractor-based model to a standard Transformer and observe dramatic improvements in sample efficiency. The second set of tasks is based on solving mathematical problems. Whereas the sorting tasks are purely relational synthetic tasks, the mathematical problem-solving tasks are more realistic and require a combination of relational reasoning and function approximation. Here too, the Abstractor yields modest but consistent improvements in performance and sample efficiency over a standard Transformer. This provides
% evidence that the Abstractor module for relational reasoning is a useful architectural addition to sequence models. 

\input{related_work}