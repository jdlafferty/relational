\section{Introduction}

The ability to infer and process relations and reason in terms of analogies lies at the heart of human abilities for abstraction and creative thinking
\citep{snow,holyoak}. This capability is largely separate from our ability to acquire semantic and procedural knowledge through sensory tasks, such as image and audio processing. Modern deep learning systems can often capture this latter type of intelligence through efficient function approximation. However, deep learning has seen limited success with relational and abstract reasoning, which requires identifying novel associations from limited data and generalizing to new domains.

Recognizing the importance of this capability, machine learning research has explored several novel frameworks for relational learning~\citep{TEM, NTM,episodicControl,shanahanExplicitlyRelationalNeural,esbn,mondal23learned,battaglia,barrett:2018,santoro1}. In this paper we propose a framework that casts relational learning in terms of Transformers. The success of Transformers lies in the use of attentional mechanisms to support richly context-sensitive processing~\citep{transformers,vaswani2017attention,kerg2020untangling}. However, it is clear that Transformers are missing core capabilities required for modeling human thought~\citep{mahowald2023dissociating}, including an ability to support analogy and abstraction.While large language models show a surprising ability to complete some analogies~\citep{webb}, this ability emerges implicitly only after processing vast amounts of data.

The Transformer architecture has the ability to model relations between objects implicitly through its attention mechanisms. However, we argue in this paper that standard attention produces entangled representations encoding a mixture of relational information and object-level features, resulting in suboptimal sample-efficiency for learning relations. The challenge is to provide ways of binding domain-specific information to low dimensional, abstract representations that can be used in a broader range of domains. In this work we propose an extension of Transformers that enables explicit relational reasoning through a novel module called the \textit{Abstractor}. At the core of the Abstractor is a variant of attention called \textit{relational cross-attention}. Our approach is motivated by an architectural inductive bias for relational learning we call the ``relational bottleneck," which separates relational information from extraneous object-level features, thus enabling more explicit relational reasoning. %Through the relational cross-attention mechanism, the Abstractor architecture creates a powerful combination of deep learning and relational learning enabling abstraction and generalization from limited data.

% Our empirical evaluation is split across three studies. In the first, we evaluate the Abstractor on simple discriminative relational tasks and compare to existing relational architectures (which so far have focused on discriminative relational tasks). In the second, we evaluate the Abstractor on a purely relational sequence-to-sequence task---sorting sequences of randomly generated objects. These experiments give us a controlled setting in which to evaluate the Abstractor's ability to model relations. We observe that the Abstractor achieves a dramatic improvement in sample efficiency compared to a standard Transformer. In the third section, we evaluate the Abstractor on a more realistic task which requires a combination of relational reasoning as well as more general sequence modeling---solving mathematical problems. We observe that the Abstractor yields modest but consistent improvements in performance and sample efficiency over a standard Transformer. This provides evidence that the Abstractor module for relational reasoning is a useful architectural addition to sequence models.

% \input{related_work}

A growing body of literature has focused on developing machine learning architectures for relational representation learning. An early example is the Relation Network~\citep{santoro1}, which proposes modeling pairwise relations by applying an MLP to the concatenation of object representations.~\citep{shanahanExplicitlyRelationalNeural} proposed the PrediNet architecture, which aims to learn representations of relations in a manner inspired by predicate logic. The ESBN model proposed in~\citep{esbn} is a memory-augmented LSTM network, inspired by ideas from cognitive science, which aims to factor representations into `sensory' and `relational'. In this sense, it is similar in spirit to the present work. Another related architecture is the CoRelNet architecture proposed in~\citep{kerg2022neural}, which reduces relational learning to modeling a similarity matrix.

The Transformer~\citep{vaswani2017attention} is a common baseline which is compared against in this literature. It is shown in these works that explicitly relational architectures outperform the Transformer, sometimes by large margins, on several synthetic discriminative relational tasks~\citep{shanahanExplicitlyRelationalNeural,esbn,kerg2022neural}. In this work, we offer an explanation, arguing that while the Transformer architecture is versatile enough to learn such relational tasks given enough data, it does not support relational reasoning explicitly. The Abstractor module extends the Transformer framework by learning representations of relations which are disentangled from extraneous object-level features.

Our experiments first validate that the Abstractor, on its own, achieves the same sample-efficiency gains of other relational architectures on discriminative relational task. We then evaluate whether the Abstractor can augment a Transformer to improve relational reasoning by evaluating on synthetic \textit{sequence-to-sequence} relational tasks, which has so far been unexplored in the literature on explicitly relational architectures. Finally, we evaluate an Abstractor-based architecture on a more realistic mathematical problem-solving task to evaluate the potential of the idea on more general tasks.

%AWNI: i've integrated the related work into the intro to save some space. the last paragraph from the intro cover some similar points as the last paragraph of the related work. i've integrated them into a single paragraph. please check if you like this and please feel free to restructure this / return the separate section for related work / add back any points i missed.