\section{Introduction}

The ability to infer and process relations and reason in terms of analogies lies at the heart of human abilities for abstraction and creative thinking
\citep{snow,holyoak}. This capability is largely separate from our ability to acquire semantic and procedural knowledge through sensory tasks, such as image and audio processing. Modern deep learning systems can often capture this latter type of intelligence through efficient function approximation. However, deep learning has seen limited success with relational and abstract reasoning, which requires identifying novel associations from limited data and generalizing to new domains.

Recognizing the importance of this capability, machine learning research has explored several novel frameworks for relational learning~\citep{TEM, NTM,episodicControl,shanahanExplicitlyRelationalNeural,esbn,mondal23learned,battaglia,barrett:2018,santoro1}. In this paper we propose a framework that casts relational learning in terms of Transformers. The success of Transformers lies in the use of attentional mechanisms to support richly context-sensitive processing~\citep{vaswani2017attention,transformers,kerg2020untangling}. However, it is clear that Transformers are missing core capabilities required for modeling human thought~\citep{mahowald2023dissociating}, including an ability to support analogy and abstraction.While large language models show a surprising ability to complete some analogies~\citep{webb}, this ability emerges implicitly only after processing vast amounts of data.

The Transformer architecture has the ability to model relations between objects implicitly through its attention mechanisms. However, we argue in this paper that standard attention produces entangled representations encoding a mixture of relational information and object-level features, resulting in suboptimal sample-efficiency for learning relations.
% The challenge is to provide ways of binding domain-specific information to low dimensional, abstract representations that can be used in a broader range of domains.
In this work we propose an extension of Transformers that enables explicit relational reasoning through a novel module called the \textit{Abstractor}. At the core of the Abstractor is a variant of attention called \textit{relational cross-attention}. Our approach is motivated by an architectural inductive bias for relational learning we call the ``relational bottleneck," which separates relational information from extraneous object-level features.
%Through the relational cross-attention mechanism, the Abstractor architecture creates a powerful combination of deep learning and relational learning enabling abstraction and generalization from limited data.

% Our empirical evaluation is split across three studies. In the first, we evaluate the Abstractor on simple discriminative relational tasks and compare to existing relational architectures (which so far have focused on discriminative relational tasks). In the second, we evaluate the Abstractor on a purely relational sequence-to-sequence task---sorting sequences of randomly generated objects. These experiments give us a controlled setting in which to evaluate the Abstractor's ability to model relations. We observe that the Abstractor achieves a dramatic improvement in sample efficiency compared to a standard Transformer. In the third section, we evaluate the Abstractor on a more realistic task which requires a combination of relational reasoning as well as more general sequence modeling---solving mathematical problems. We observe that the Abstractor yields modest but consistent improvements in performance and sample efficiency over a standard Transformer. This provides evidence that the Abstractor module for relational reasoning is a useful architectural addition to sequence models.

% \input{related_work}

A growing body of literature has focused on developing machine learning architectures for relational representation learning. An early example is the Relation Network~\citep{santoro1}, which proposes modeling pairwise relations by applying an MLP to the concatenation of object representations.~\citet{shanahanExplicitlyRelationalNeural} proposed the PrediNet architecture, which aims to learn representations of relations in a manner inspired by predicate logic. The ESBN model proposed by~\citet{esbn} is a memory-augmented LSTM network which aims to factor representations into `sensory' and `relational'. Another related architecture is CoRelNet, proposed in~\citep{kerg2022neural}, which reduces relational learning to modeling a similarity matrix. More recently,~\citet{altabaaRelationalConvolutionalNetworks2023} tackled the problem of learning representations of hierarchical relations by formalizing a notion of ``relational convolution''.

The Transformer is a common baseline which is compared against in this literature. These works show that explicitly relational architectures outperform the Transformer on several synthetic discriminative relational tasks, sometimes by large margins~\citep{shanahanExplicitlyRelationalNeural,esbn,kerg2022neural,altabaaRelationalConvolutionalNetworks2023}. We offer an explanation, arguing that while the Transformer architecture is versatile enough to learn such relational tasks given enough data, it does not support relational representation explicitly. The Abstractor extends the Transformer framework by learning representations of relations that are disentangled from extraneous object-level features.

Our experiments first compare the Abstractor to other relational architectures on discriminative relational tasks, finding that the Abstractor is both more flexible and achieves superior sample efficiency. We then evaluate whether the Abstractor can augment a Transformer to improve relational reasoning by evaluating on synthetic \textit{sequence-to-sequence} relational tasks, which has so far been unexplored in the literature on explicitly relational architectures. Finally, we evaluate an Abstractor-supported architecture on a set of mathematical problem-solving tasks to evaluate the potential of the idea on tasks more representative of real-world applications. We observe consistent, sometimes dramatic, gains in sample-efficiency.