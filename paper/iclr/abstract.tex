\begin{abstract}
    An extension of Transformers is proposed that enables explicit relational reasoning through a novel module called the \textit{Abstractor}.
    At the core of the Abstractor module is a variant of attention called \textit{relational cross-attention}.
    The approach is motivated by an architectural inductive bias for relational learning called the ``relational bottleneck," 
    which separates relational information from extraneous sensory information, to  enable more focused and explicit relational reasoning,
    leading to abstraction and generalization from limited data.
    In addition to evaluating the Abstractor on simple discriminative relational tasks and comparing to existing relational architectures, 
    we also evaluate the Abstractor on relational sequence-to-sequence tasks, 
    observing dramatic improvements in sample efficiency compared to a standard Transformer. We also evaluate the Abstractor on a collection of mathematics problems that benefit from a combination of relational reasoning and more traditional sequence modeling.
 \end{abstract}