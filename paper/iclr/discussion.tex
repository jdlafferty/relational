\section{Discussion}\label{sec:discuss}

% In this work we have proposed a framework which extends Transformer models to naturally support types of relational learning, through a cross-attention mechanism that enforces a relational bottleneck, separating relational information from object-level attributes. Building on insights gained from the implementation of a relational bottleneck in other forms \citep{esbn, kerg2022neural}, this exploits the powerful attentional capabilities of the transformer architecture to identify relevant relationships. Our experiments validate that the proposed architecture enables dramatic improvements in relational processing, and that this has the potential to translate into meaningful gains in more general sequence modeling tasks.
% % Experiments with controlled purely relational tasks as well as more general sequence modeling tasks indicate that this framework has the potential to combine the benefits of function approximation over sensory states, as exploited in many deep learning models, with abstraction and relational reasoning abilities supported by symbolic processing.
% Interesting work remains to better understand the potential of this framework, and how it may relate to the algorithms of human cognition as implemented in the brain.

\textbf{Summary.} In this work, we proposed a variant of attention which produces representations of relational information disentangled from object-level attributes. This gives rise to the Abstractor module, which fits naturally into the powerful framework of Transformers. Through a series of experiments, we demonstrate the potential of this proposal in controlled purely relational tasks as well as more general sequence modeling tasks.

\textbf{Future work.} The initial proposal of this work opens several avenues for future research. One possible line of research is concerned with better-understanding the role of symbols within the Abstractor. This includes evaluating the trade-offs between learned symbols and non-parametric symbols, as well as exploring the formulation of relational cross-attention with position-relative symbols. Another important line of research is the study of the alternative architectural variants proposed in~\Cref{fig:abstractor_architectures}. For instance, understanding the properties of compositions of Abstractor modules and assessing such an architecture's ability to represent higher-order relations. Finally, while the experiments presented here demonstrate the Abstractor's promise and utility for relational representation in Transformers, there is a need for more extensive experiments on tasks with ``real-world application,'' such as standard language modeling.