\section{Conclusion}\label{sec:discuss}

% In this work we have proposed a framework which extends Transformer models to naturally support types of relational learning, through a cross-attention mechanism that enforces a relational bottleneck, separating relational information from object-level attributes. Building on insights gained from the implementation of a relational bottleneck in other forms \citep{esbn, kerg2022neural}, this exploits the powerful attentional capabilities of the transformer architecture to identify relevant relationships. Our experiments validate that the proposed architecture enables dramatic improvements in relational processing, and that this has the potential to translate into meaningful gains in more general sequence modeling tasks.
% % Experiments with controlled purely relational tasks as well as more general sequence modeling tasks indicate that this framework has the potential to combine the benefits of function approximation over sensory states, as exploited in many deep learning models, with abstraction and relational reasoning abilities supported by symbolic processing.
% Interesting work remains to better understand the potential of this framework, and how it may relate to the algorithms of human cognition as implemented in the brain.

In this work, we propose a variant of attention that produces representations of relational information disentangled from object-level attributes. This leads to the development of the Abstractor module, which fits naturally into the powerful framework of Transformers. Through a series of experiments, we demonstrate the potential of this new framework to achieve gains in sample efficiency in both purely relational tasks and more general sequence modeling tasks. This work opens up several avenues for future research, including better-understanding the the strengths and weaknesses of different architectural variants, work towards a more streamlined scalable architecture, and exploring the framework's use in increasingly complex real-world problems.

% This work opens up several avenues for future research. One possible line of research is to better understand the role of symbols within the Abstractor, including the trade-offs between learned symbols, positional and position-relative symbols, and symbols that encode syntactic roles. Another important line of research is the study of the alternative architectural variants proposed in~\Cref{fig:abstractor_architectures}. For example, understanding the properties of compositions of Abstractor modules and assessing such an architecture's ability to represent higher-order relations will shed light on the expressive power of the framework. Finally, the experiments presented here demonstrate the Abstractor's promise and utility for relational representation in Transformers, and it will be interesting to explore the framework's use in increasingly complex modeling problems.