{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"source":["# Autoregressive Abstracter: Card Sorting\n","\n","This is a second development version of `autoregressive_abstracter_card_sorting.ipynb`. In the first version of the notebook, the transformer successfully completed the task, but the $\\text[{encoder}] \\to [\\text{abstracter}] \\to [\\text{decoder}]$ models failed. Here, we try a couple more configurations of the abstracter models. In particular,\n","\n","1) Standard encoder with self-attention. Abstracter with self-attention and relational cross-attention ($Q=E, K=E, V=A$). Decoder with causal self-attention and relational cross-attention with ($Q=A, K=A, V=E$).\n","\n","2) Standard encoder with self-attention. Abstracter with self-attention and relational or symbolic cross-attention. Decoder with causal self-attention and standard cross-attention with ($Q=D, K=A, V=A$). (so far, as in the first version of the notebook). Then, final prediction is generated via $t_j \\sim \\text{Multinomial}(\\text{Softmax}(D_j^\\top a_1, ..., D_j^\\top a_L))$"]},{"cell_type":"markdown","metadata":{},"source":["## Set Up"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:32.825823Z","iopub.status.busy":"2023-01-22T00:19:32.825425Z","iopub.status.idle":"2023-01-22T00:19:37.939551Z","shell.execute_reply":"2023-01-22T00:19:37.938258Z","shell.execute_reply.started":"2023-01-22T00:19:32.825776Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-01-29 15:33:06.678075: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import pydealer\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import sklearn.metrics\n","\n","from hand2hand import Cards\n","import utils"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:37.942302Z","iopub.status.busy":"2023-01-22T00:19:37.941072Z","iopub.status.idle":"2023-01-22T00:19:41.286946Z","shell.execute_reply":"2023-01-22T00:19:41.285723Z","shell.execute_reply.started":"2023-01-22T00:19:37.942249Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["env: \"WANDB_NOTEBOOK_NAME\"=\"autoregressive_abstracter_hand_sorting_new_ideas.ipynb\"\n"]},{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mawni00\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/plain":["True"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["%env \"WANDB_NOTEBOOK_NAME\" \"autoregressive_abstracter_hand_sorting_new_ideas.ipynb\"\n","\n","import wandb\n","wandb.login()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:41.291134Z","iopub.status.busy":"2023-01-22T00:19:41.290307Z","iopub.status.idle":"2023-01-22T00:19:41.299006Z","shell.execute_reply":"2023-01-22T00:19:41.297858Z","shell.execute_reply.started":"2023-01-22T00:19:41.291090Z"},"trusted":true},"outputs":[],"source":["def create_callbacks(monitor='loss', log_gradients=False, save_model=True, log_weights=True,\n","                     train_ds=None, val_ds=None, ):\n","    callbacks = [\n","#         tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, mode='auto', restore_best_weights=True),\n","#         tf.keras.callbacks.ReduceLROnPlateau( monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto'),\n","        wandb.keras.WandbMetricsLogger(log_freq='epoch'),\n","        wandb.keras,WandbModelCheckpoint(monitor=monitor, mode='auto', save_freq='epoch')\n","#         wandb.keras.WandbCallback(\n","#             monitor=monitor, log_weights=log_weights, log_gradients=log_gradients, save_model=save_model, save_graph=True,\n","#             training_data=train_ds, validation_data=val_ds,\n","#             labels=class_names, predictions=64, compute_flops=True)\n","        ]\n","    return callbacks\n","\n","# metrics = [\n","#         tf.keras.metrics.BinaryAccuracy(name='acc'),\n","#         tf.keras.metrics.Precision(class_id=1, name='precision'),\n","#         tf.keras.metrics.Recall(class_id=1, name='recall'),\n","#         tf.keras.metrics.AUC(curve='ROC', multi_label=True, name='auc')\n","#         ]\n","\n","# loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n","# opt = tf.keras.optimizers.Adam()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:41.301050Z","iopub.status.busy":"2023-01-22T00:19:41.300665Z","iopub.status.idle":"2023-01-22T00:19:41.337052Z","shell.execute_reply":"2023-01-22T00:19:41.336010Z","shell.execute_reply.started":"2023-01-22T00:19:41.301016Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import seq2seq_transformer\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import layers, Model"]},{"cell_type":"markdown","metadata":{},"source":["## Define New Layers (New Variants of Cross-Attention for Decoder)\n","\n","Define New variant of Decoder with $Q=A, K=A, V=E$"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["# implement a general cross-attention layer which supports all the different kinds of attention\n","\n","from seq2seq_transformer import BaseAttention\n","\n","class ContextualCrossAttention(BaseAttention):\n","    \"\"\"A general layer for implementing cross-attention, with configurable queries, keys, and values\"\"\"\n","\n","    def __init__(self, cross_attention_type='standard', **kwargs):\n","        \n","        super(ContextualCrossAttention, self).__init__(**kwargs)\n","\n","        if cross_attention_type in ('std_encoder_decoder', 'symbolic', 'relational'):\n","            self.cross_attention_type = cross_attention_type\n","        else:\n","            raise ValueError(f'`cross_attention_type` {cross_attention_type} is invalid')\n","\n","    def call(self, input_seq, context_seq):\n","\n","        if self.cross_attention_type == 'std_encoder_decoder':\n","            # standard encoder-decoder cross-attention of transformers\n","            attn_output, attn_scores = self.mha(\n","                query=input_seq,\n","                key=context_seq,\n","                value=context_seq,\n","                return_attention_scores=True)\n","            \n","            x = self.add([input_seq, attn_output])\n","\n","            x = self.layernorm(x)\n","\n","        elif self.cross_attention_type == 'symbolic':\n","            # 'symbolic' cross-attention.\n","            #  input_seq is learned input-independent symbols\n","            attn_output, attn_scores = self.mha(\n","                query=input_seq,\n","                key=context_seq,\n","                value=input_seq,\n","                return_attention_scores=True)\n","            \n","            x = self.add([input_seq, attn_output]) # TODO: think about this. should we keep this skip connection?\n","\n","            x = self.layernorm(x)\n","        \n","        elif self.cross_attention_type == 'relational':\n","            # 'relational' cross-attention. \n","            # queries and keys both come from the context sequence, thus their inner product computes relations\n","            attn_output, attn_scores = self.mha(\n","                query=context_seq,\n","                key=context_seq,\n","                value=input_seq,\n","                return_attention_scores=True)\n","            \n","            x = self.add([input_seq, attn_output]) # TODO: think about this. should we keep this skip connection?\n","\n","            x = self.layernorm(x)\n","\n","        else:\n","            raise ValueError('unexpected `cross_attention_type`')\n","\n","        # Cache the attention scores for plotting later.\n","        self.last_attn_scores = attn_scores\n","\n","\n","        return x"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["from seq2seq_transformer import CausalSelfAttention, FeedForward\n","\n","class ContextDecoderLayer(tf.keras.layers.Layer):\n","  def __init__(self,\n","               d_model,\n","               num_heads,\n","               dff,\n","               cross_attention_type='std_encoder_decoder',\n","               dropout_rate=0.1):\n","    \n","    super(ContextDecoderLayer, self).__init__()\n","    \n","    self.cross_attention_type = cross_attention_type\n","\n","    self.causal_self_attention = CausalSelfAttention(\n","        num_heads=num_heads,\n","        key_dim=d_model,\n","        dropout=dropout_rate)\n","\n","    self.cross_attention = ContextualCrossAttention(\n","        num_heads=num_heads,\n","        key_dim=d_model,\n","        dropout=dropout_rate,\n","        cross_attention_type=self.cross_attention_type)\n","\n","    self.ffn = FeedForward(d_model, dff)\n","\n","  def call(self, input_seq, context_seq):\n","    x = self.causal_self_attention(x=input_seq)\n","    x = self.cross_attention(input_seq=x, context_seq=context_seq)\n","\n","    # Cache the last attention scores for plotting later\n","    self.last_attn_scores = self.cross_attention.last_attn_scores\n","\n","    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n","\n","    return x\n","\n","\n","class ContextDecoder(tf.keras.layers.Layer):\n","    def __init__(\n","        self, \n","        num_layers, \n","        num_heads,\n","        dff,\n","        cross_attention_type='std_encoder_decoder',\n","        dropout_rate=0.1,\n","        name='decoder'):\n","\n","        super(ContextDecoder, self).__init__(name=name)\n","\n","        self.cross_attention_type = cross_attention_type\n","        self.num_layers = num_layers\n","        self.num_heads = num_heads\n","        self.dff = dff\n","        self.dropout_rate = dropout_rate\n","\n","    def build(self, input_shape):\n","\n","        _, self.sequence_length, self.d_model = input_shape\n","\n","        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n","\n","        self.dec_layers = [\n","            ContextDecoderLayer(\n","                d_model=self.d_model, num_heads=self.num_heads,\n","                dff=self.dff, dropout_rate=self.dropout_rate, \n","                cross_attention_type=self.cross_attention_type)\n","            for _ in range(self.num_layers)]\n","\n","        self.last_attn_scores = None\n","\n","    def call(self, input_seq, context_seq):\n","\n","        x = self.dropout(input_seq)\n","\n","        for i in range(self.num_layers):\n","            x = self.dec_layers[i](input_seq=x, context_seq=context_seq)\n","\n","#             self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n","\n","        return x"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["# # define standard decoder with above implementation of Cross-Attention Layer\n","# class Decoder(tf.keras.layers.Layer):\n","#     def __init__(self, num_layers, num_heads, dff,\n","#                dropout_rate=0.1, name='decoder'):\n","#         super(Decoder, self).__init__(name=name)\n","\n","#         self.num_layers = num_layers\n","#         self.num_heads = num_heads\n","#         self.dff = dff\n","#         self.dropout_rate = dropout_rate\n","\n","#     def build(self, input_shape):\n","\n","#         _, self.sequence_length, self.d_model = input_shape\n","\n","#         self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n","\n","#         self.dec_layers = [\n","#             ContextDecoderLayer(\n","#                 d_model=self.d_model, num_heads=self.num_heads,\n","#                 dff=self.dff, dropout_rate=self.dropout_rate,\n","#                 cross_attention_type='std_encoder_decoder')\n","#             for _ in range(self.num_layers)]\n","\n","#         self.last_attn_scores = None\n","\n","#     def call(self, input_seq, context_seq):\n","\n","#         x = self.dropout(input_seq)\n","\n","#         for i in range(self.num_layers):\n","#             x = self.dec_layers[i](input_seq=x, context_seq=context_seq)\n","\n","# #             self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n","\n","#         return x\n"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:41.352089Z","iopub.status.busy":"2023-01-22T00:19:41.351083Z","iopub.status.idle":"2023-01-22T00:19:41.456352Z","shell.execute_reply":"2023-01-22T00:19:41.455299Z","shell.execute_reply.started":"2023-01-22T00:19:41.352040Z"},"trusted":true},"outputs":[],"source":["hand_size = 7\n","\n","deck = Cards()\n","pydeck = pydealer.Deck()\n","pydeck.shuffle()"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:41.458588Z","iopub.status.busy":"2023-01-22T00:19:41.458119Z","iopub.status.idle":"2023-01-22T00:19:42.130175Z","shell.execute_reply":"2023-01-22T00:19:42.128980Z","shell.execute_reply.started":"2023-01-22T00:19:41.458540Z"},"trusted":true},"outputs":[],"source":["n = 10000\n","BEGIN_HAND = 52 # token for 'beginning of hand'\n","END_HAND = 53 # token for 'end of hand'\n","\n","hands = np.array(n*(hand_size+2)*[0]).reshape(n, hand_size+2)\n","hands_sorted = np.array(n*(hand_size+2)*[0]).reshape(n, hand_size+2)\n","\n","for i in np.arange(n):\n","    hand = pydeck.deal(hand_size)\n","    if len(hand) < hand_size:\n","        #print('shuffling deck')\n","        pydeck = pydealer.Deck()\n","        pydeck.shuffle()\n","        hand = pydeck.deal(hand_size)\n","    source = list(deck.index_pyhand(hand))\n","    source.insert(0,BEGIN_HAND)\n","    source.append(END_HAND)\n","    hands[i] = np.array(source)\n","    deck.sort_pyhand(hand)\n","    target = list(deck.index_pyhand(hand))\n","    target.insert(0,BEGIN_HAND)\n","    target.append(END_HAND)\n","    hands_sorted[i] = np.array(target)\n"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:42.132840Z","iopub.status.busy":"2023-01-22T00:19:42.131922Z","iopub.status.idle":"2023-01-22T00:19:42.144150Z","shell.execute_reply":"2023-01-22T00:19:42.143014Z","shell.execute_reply.started":"2023-01-22T00:19:42.132791Z"},"trusted":true},"outputs":[],"source":["hands_train, hands_test, sorted_train, sorted_test = train_test_split(hands, hands_sorted, test_size=0.25)\n","\n","source_train = hands_train\n","target_train = sorted_train[:,:-1]\n","labels_train = sorted_train[:,1:]\n","\n","source_test = hands_test\n","target_test = sorted_test[:,:-1]\n","labels_test = sorted_test[:,1:]"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:42.149921Z","iopub.status.busy":"2023-01-22T00:19:42.149555Z","iopub.status.idle":"2023-01-22T00:19:42.157219Z","shell.execute_reply":"2023-01-22T00:19:42.156323Z","shell.execute_reply.started":"2023-01-22T00:19:42.149888Z"},"trusted":true},"outputs":[],"source":["def evaluate_seq2seq_model(model):\n","    n = len(source_test)\n","    output = np.zeros(n*(hand_size+2), dtype=int).reshape(n,hand_size+2)\n","    output[:,0] = BEGIN_HAND\n","    for i in range(hand_size+1):\n","        predictions = model((source_test, output[:, :-1]), training=False)\n","        predictions = predictions[:, i, :]\n","        predicted_id = tf.argmax(predictions, axis=-1)\n","        output[:,i+1] = predicted_id\n","\n","    acc = (np.sum(output[:,1:] == labels_test))/np.prod(labels_test.shape)\n","    print('per-card accuracy: %.2f%%' % (100*acc))\n","    \n","    return acc"]},{"cell_type":"markdown","metadata":{},"source":["## Standard Transformer"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:42.159418Z","iopub.status.busy":"2023-01-22T00:19:42.158612Z","iopub.status.idle":"2023-01-22T00:19:42.168515Z","shell.execute_reply":"2023-01-22T00:19:42.167459Z","shell.execute_reply.started":"2023-01-22T00:19:42.159385Z"},"trusted":true},"outputs":[],"source":["# from seq2seq_transformer import Encoder\n","\n","# inputs = layers.Input(shape=(9,), name='token_input')\n","# target = layers.Input(shape=(8,), name='token_target')\n","\n","# token_embedder = layers.Embedding(54, 128, name='vector_embedding')\n","# pos_embedding_adder_input = AddPositionalEmbedding(name='add_pos_embedding_input')\n","# pos_embedding_adder_target = AddPositionalEmbedding(name='add_pos_embedding_target')\n","# encoder = Encoder(num_layers=3, num_heads=2, dff=64, dropout_rate=0.1, name='transformer_encoder')\n","\n","# decoder = Decoder(num_layers=3, num_heads=2, dff=64, dropout_rate=0.1, name='transformer_decoder')\n","\n","# x = token_embedder(inputs)\n","# x = pos_embedding_adder_input(x)\n","\n","# encoder_context = encoder(x)\n","\n","# target_embedding = token_embedder(target)\n","# target_embedding = pos_embedding_adder_target(target_embedding)\n","\n","# x = decoder(target_embedding, encoder_context)\n","\n","# x = layers.Dense(54)(x)\n","\n","# transformer = Model(inputs=[inputs, target], outputs=x)"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:42.170519Z","iopub.status.busy":"2023-01-22T00:19:42.170184Z","iopub.status.idle":"2023-01-22T00:19:42.184907Z","shell.execute_reply":"2023-01-22T00:19:42.183984Z","shell.execute_reply.started":"2023-01-22T00:19:42.170482Z"},"trusted":true},"outputs":[],"source":["from seq2seq_transformer import Encoder, AddPositionalEmbedding\n","\n","class Transformer(tf.keras.Model):\n","    def __init__(self, num_layers, num_heads, dff,\n","            input_vocab_size, target_vocab_size, embedding_dim,\n","            dropout_rate=0.1, name='transformer'):\n","        super().__init__(name=name)\n","        \n","        self.token_embedder = layers.Embedding(input_vocab_size, embedding_dim, name='vector_embedding')\n","        \n","        self.pos_embedding_adder_input = AddPositionalEmbedding(name='add_pos_embedding_input')\n","        self.pos_embedding_adder_target = AddPositionalEmbedding(name='add_pos_embedding_target')\n","\n","        self.encoder = Encoder(num_layers=num_layers, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate, name='encoder')\n","        self.decoder = ContextDecoder(num_layers=num_layers, num_heads=num_heads, dff=dff,\n","          dropout_rate=dropout_rate, cross_attention_type='std_encoder_decoder', name='decoder')\n","        self.final_layer = layers.Dense(target_vocab_size, name='final_layer')\n","\n","\n","    def call(self, inputs):\n","        # To use a Keras model with `.fit` you must pass all your inputs in the\n","        # first argument.\n","        source, target  = inputs\n","        \n","        x = self.token_embedder(source)\n","        x = self.pos_embedding_adder_input(x)\n","\n","        encoder_context = self.encoder(x)\n","\n","        target_embedding = self.token_embedder(target)\n","        target_embedding = self.pos_embedding_adder_target(target_embedding)\n","\n","        x = self.decoder(input_seq=target_embedding, context_seq=encoder_context)\n","\n","        # Final linear layer output.\n","        logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n","\n","        try:\n","          # Drop the keras mask, so it doesn't scale the losses/metrics.\n","          # b/250038731\n","          del logits._keras_mask\n","        except AttributeError:\n","          pass\n","\n","        # Return the final output and the attention weights.\n","        return logits"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:42.186646Z","iopub.status.busy":"2023-01-22T00:19:42.186273Z","iopub.status.idle":"2023-01-22T00:19:42.260989Z","shell.execute_reply":"2023-01-22T00:19:42.259670Z","shell.execute_reply.started":"2023-01-22T00:19:42.186612Z"},"trusted":true},"outputs":[],"source":["transformer = Transformer(num_layers=2, num_heads=2, dff=64, \n","    input_vocab_size=54, target_vocab_size=54, embedding_dim=128)"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:42.264053Z","iopub.status.busy":"2023-01-22T00:19:42.263175Z","iopub.status.idle":"2023-01-22T00:19:57.966856Z","shell.execute_reply":"2023-01-22T00:19:57.958473Z","shell.execute_reply.started":"2023-01-22T00:19:42.264009Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"transformer\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," vector_embedding (Embedding  multiple                 6912      \n"," )                                                               \n","                                                                 \n"," add_pos_embedding_input (Ad  multiple                 0         \n"," dPositionalEmbedding)                                           \n","                                                                 \n"," add_pos_embedding_target (A  multiple                 0         \n"," ddPositionalEmbedding)                                          \n","                                                                 \n"," encoder (Encoder)           multiple                  298112    \n","                                                                 \n"," decoder (ContextDecoder)    multiple                  562560    \n","                                                                 \n"," final_layer (Dense)         multiple                  6966      \n","                                                                 \n","=================================================================\n","Total params: 874,550\n","Trainable params: 874,550\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["from seq2seq_transformer import masked_loss, masked_accuracy\n","\n","# opt.build(transformer.trainable_variables)\n","transformer.compile(loss=masked_loss, optimizer=tf.keras.optimizers.Adam(), metrics=masked_accuracy)\n","transformer((source_train, target_train))\n","\n","transformer.summary()"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"data":{"text/plain":["[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n"," PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["tf.config.list_physical_devices()"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:19:57.978487Z","iopub.status.busy":"2023-01-22T00:19:57.975916Z","iopub.status.idle":"2023-01-22T00:22:34.015330Z","shell.execute_reply":"2023-01-22T00:22:34.013372Z","shell.execute_reply.started":"2023-01-22T00:19:57.978310Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["2023-01-29 15:38:49.983086: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x2ac644012810 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-01-29 15:38:49.983174: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2023-01-29 15:38:50.266978: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","2023-01-29 15:38:50.346269: W tensorflow/compiler/xla/service/gpu/nvptx_helper.cc:56] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n","Searched for CUDA in the following directories:\n","  ./cuda_sdk_lib\n","  /usr/local/cuda-11.2\n","  /usr/local/cuda\n","  .\n","You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n","2023-01-29 15:38:50.355417: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.355986: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","2023-01-29 15:38:50.356202: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.407747: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.408246: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.442354: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.442657: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.473241: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.473530: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.504412: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.504697: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.534924: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.535237: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.565004: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.565300: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.594914: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.595225: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.624682: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.624963: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.654793: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.655075: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.684869: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.685162: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.715196: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.715483: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.745428: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.745750: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.772617: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.772897: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.798433: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.798673: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.823682: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.823923: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.849299: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.849543: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.874672: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.874909: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.900025: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.900279: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.925216: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.925460: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.950370: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.950609: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.975859: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:50.976128: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.001300: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.001553: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.026705: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.026990: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.052113: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.052354: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.077593: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.077851: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.102741: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.103011: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.128232: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.128474: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.153599: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.153876: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.178755: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.179033: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.204055: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.204344: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.229349: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.229603: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.254435: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.254689: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.279720: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.279961: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.305099: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.305347: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.330531: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.330812: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.355789: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.356030: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.381161: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.381402: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.406620: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.406865: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.432001: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.432258: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.457493: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.457738: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.482845: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.483085: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.508316: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.508575: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.533787: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.534034: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.559215: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.559454: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.584591: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.584830: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.609777: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.610018: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.635221: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.635465: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.660428: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.660671: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.685887: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.686137: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.711252: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.711494: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.736630: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.736873: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.761900: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.762166: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.787220: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.787463: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.812453: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.812693: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.837766: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.838020: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.863199: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.863442: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.888602: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.888848: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.914023: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.914276: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.939521: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.939777: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.964618: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.964861: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.990054: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:51.990345: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.015160: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.015401: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.040585: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.040824: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.066205: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.066463: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.091635: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.091915: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.117063: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.117354: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.142608: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.142852: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.168186: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.168424: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.194002: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.194298: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.219211: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.219455: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.244455: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.244697: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.269660: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.269901: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.295008: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.295268: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.320147: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.320392: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.345656: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.345896: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.371697: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.371948: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.397253: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.397509: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.422402: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.422642: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.447813: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.448057: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.473794: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.474054: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.499183: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.499466: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.524590: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.524874: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.549928: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.550226: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.575521: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.575764: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.602197: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.602479: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.634417: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n","2023-01-29 15:38:52.634754: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc\n"]},{"ename":"InternalError","evalue":"Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_86' defined at (most recent call last):\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n      app.start()\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 724, in start\n      self.io_loop.start()\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 512, in dispatch_queue\n      await self.process_one()\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 501, in process_one\n      await dispatch(*args)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 408, in dispatch_shell\n      await result\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 731, in execute_request\n      reply_content = await reply_content\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 417, in do_execute\n      res = shell.run_cell(\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/tmp.YpQxWfuT6Q/ipykernel_22645/144498288.py\", line 1, in <module>\n      transformer.fit((source_train, target_train), labels_train, epochs=10, batch_size=64, verbose=1)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/engine/training.py\", line 1027, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 527, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1140, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 634, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1166, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1216, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1211, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_86'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node StatefulPartitionedCall_86}}]] [Op:__inference_train_function_14144]","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)","Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_86' defined at (most recent call last):\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n      app.start()\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 724, in start\n      self.io_loop.start()\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 512, in dispatch_queue\n      await self.process_one()\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 501, in process_one\n      await dispatch(*args)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 408, in dispatch_shell\n      await result\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 731, in execute_request\n      reply_content = await reply_content\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 417, in do_execute\n      res = shell.run_cell(\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/tmp.YpQxWfuT6Q/ipykernel_22645/144498288.py\", line 1, in <module>\n      transformer.fit((source_train, target_train), labels_train, epochs=10, batch_size=64, verbose=1)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/engine/training.py\", line 1027, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 527, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1140, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 634, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1166, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1216, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/gpfs/gibbs/project/lafferty/ma2393/conda_envs/relml/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1211, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_86'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node StatefulPartitionedCall_86}}]] [Op:__inference_train_function_14144]"]}],"source":["transformer.fit((source_train, target_train), labels_train, epochs=10, batch_size=64, verbose=1)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:22:34.017664Z","iopub.status.busy":"2023-01-22T00:22:34.017108Z","iopub.status.idle":"2023-01-22T00:22:41.856039Z","shell.execute_reply":"2023-01-22T00:22:41.854674Z","shell.execute_reply.started":"2023-01-22T00:22:34.017618Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["per-card accuracy: 94.40%\n"]}],"source":["evaluate_seq2seq_model(transformer);"]},{"cell_type":"markdown","metadata":{},"source":["## Autoregressive Abstracter with 'Symbolic' Cross-Attention $(Q=A, K=E, V=A)$"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:25:18.852376Z","iopub.status.busy":"2023-01-22T00:25:18.851544Z","iopub.status.idle":"2023-01-22T00:25:18.868511Z","shell.execute_reply":"2023-01-22T00:25:18.867263Z","shell.execute_reply.started":"2023-01-22T00:25:18.852334Z"},"trusted":true},"outputs":[],"source":["from symbolic_decoder import SymbolicDecoder\n","\n","class AutoregressiveSymbolicAbstracter(tf.keras.Model):\n","    def __init__(self, num_layers, num_heads, dff,\n","            input_vocab_size, target_vocab_size, embedding_dim,\n","            dropout_rate=0.1, name='transformer'):\n","        super().__init__(name=name)\n","        \n","        self.token_embedder = layers.Embedding(input_vocab_size, embedding_dim, name='vector_embedding')\n","        \n","        self.pos_embedding_adder_input = AddPositionalEmbedding(name='add_pos_embedding_input')\n","        self.pos_embedding_adder_target = AddPositionalEmbedding(name='add_pos_embedding_target')\n","\n","        self.encoder = Encoder(num_layers=num_layers, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate, name='encoder')\n","        self.abstracter = SymbolicDecoder(num_layers=num_layers, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate, name='abstracter')\n","        self.decoder = Decoder(num_layers=num_layers, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate, name='decoder')\n","        self.final_layer = layers.Dense(target_vocab_size, name='final_layer')\n","\n","\n","    def call(self, inputs):\n","        # To use a Keras model with `.fit` you must pass all your inputs in the\n","        # first argument.\n","        source, target  = inputs\n","        \n","        x = self.token_embedder(source)\n","        x = self.pos_embedding_adder_input(x)\n","\n","        encoder_context = self.encoder(x)\n","\n","        abstracted_context = self.abstracter(encoder_context)\n","        \n","        target_embedding = self.token_embedder(target)\n","        target_embedding = self.pos_embedding_adder_target(target_embedding)\n","\n","        x = self.decoder(target_embedding, abstracted_context)\n","\n","        # Final linear layer output.\n","        logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n","\n","        try:\n","          # Drop the keras mask, so it doesn't scale the losses/metrics.\n","          # b/250038731\n","          del logits._keras_mask\n","        except AttributeError:\n","          pass\n","\n","        # Return the final output and the attention weights.\n","        return logits"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:25:19.673456Z","iopub.status.busy":"2023-01-22T00:25:19.672765Z","iopub.status.idle":"2023-01-22T00:25:19.689969Z","shell.execute_reply":"2023-01-22T00:25:19.688741Z","shell.execute_reply.started":"2023-01-22T00:25:19.673418Z"},"trusted":true},"outputs":[],"source":["autoregressive_symbolic_abstracter = AutoregressiveSymbolicAbstracter(num_layers=2, num_heads=2, dff=64, \n","    input_vocab_size=54, target_vocab_size=54, embedding_dim=128)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:25:22.778048Z","iopub.status.busy":"2023-01-22T00:25:22.777587Z","iopub.status.idle":"2023-01-22T00:25:31.420272Z","shell.execute_reply":"2023-01-22T00:25:31.419027Z","shell.execute_reply.started":"2023-01-22T00:25:22.778010Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"transformer\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," vector_embedding (Embedding  multiple                 6912      \n"," )                                                               \n","                                                                 \n"," add_pos_embedding_input (Ad  multiple                 0         \n"," dPositionalEmbedding)                                           \n","                                                                 \n"," add_pos_embedding_target (A  multiple                 0         \n"," ddPositionalEmbedding)                                          \n","                                                                 \n"," encoder (Encoder)           multiple                  298112    \n","                                                                 \n"," abstracter (SymbolicDecoder  multiple                 563712    \n"," )                                                               \n","                                                                 \n"," decoder (Decoder)           multiple                  562560    \n","                                                                 \n"," final_layer (Dense)         multiple                  6966      \n","                                                                 \n","=================================================================\n","Total params: 1,438,262\n","Trainable params: 1,438,262\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["from seq2seq_transformer import masked_loss, masked_accuracy\n","\n","autoregressive_symbolic_abstracter.compile(loss=masked_loss, optimizer=tf.keras.optimizers.Adam(), metrics=masked_accuracy)\n","autoregressive_symbolic_abstracter((source_train, target_train))\n","\n","autoregressive_symbolic_abstracter.summary()"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:25:31.422874Z","iopub.status.busy":"2023-01-22T00:25:31.422487Z","iopub.status.idle":"2023-01-22T00:29:12.464426Z","shell.execute_reply":"2023-01-22T00:29:12.463132Z","shell.execute_reply.started":"2023-01-22T00:25:31.422837Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","118/118 [==============================] - 37s 155ms/step - loss: 2.7072 - masked_accuracy: 0.2062\n","Epoch 2/10\n","118/118 [==============================] - 17s 143ms/step - loss: 2.4253 - masked_accuracy: 0.2270\n","Epoch 3/10\n","118/118 [==============================] - 16s 139ms/step - loss: 2.3988 - masked_accuracy: 0.2312\n","Epoch 4/10\n","118/118 [==============================] - 17s 141ms/step - loss: 2.3879 - masked_accuracy: 0.2324\n","Epoch 5/10\n","118/118 [==============================] - 17s 140ms/step - loss: 2.3818 - masked_accuracy: 0.2337\n","Epoch 6/10\n","118/118 [==============================] - 17s 144ms/step - loss: 2.3711 - masked_accuracy: 0.2343\n","Epoch 7/10\n","118/118 [==============================] - 17s 142ms/step - loss: 2.3671 - masked_accuracy: 0.2350\n","Epoch 8/10\n","118/118 [==============================] - 17s 147ms/step - loss: 2.3638 - masked_accuracy: 0.2361\n","Epoch 9/10\n","118/118 [==============================] - 17s 146ms/step - loss: 2.3588 - masked_accuracy: 0.2378\n","Epoch 10/10\n","118/118 [==============================] - 17s 141ms/step - loss: 2.3561 - masked_accuracy: 0.2367\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7ff0acda1c50>"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["autoregressive_symbolic_abstracter.fit((source_train, target_train), labels_train, epochs=10, batch_size=64, verbose=1)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:29:12.466381Z","iopub.status.busy":"2023-01-22T00:29:12.466013Z","iopub.status.idle":"2023-01-22T00:29:24.289259Z","shell.execute_reply":"2023-01-22T00:29:24.288227Z","shell.execute_reply.started":"2023-01-22T00:29:12.466349Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["per-card accuracy: 15.85%\n"]}],"source":["evaluate_seq2seq_model(autoregressive_symbolic_abstracter);"]},{"cell_type":"markdown","metadata":{},"source":["## Autoregressive Abstracter with 'Episodic' Cross-Attention $(Q=E, K=E, V=E)$"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:29:24.292067Z","iopub.status.busy":"2023-01-22T00:29:24.291686Z","iopub.status.idle":"2023-01-22T00:29:24.309560Z","shell.execute_reply":"2023-01-22T00:29:24.308461Z","shell.execute_reply.started":"2023-01-22T00:29:24.292034Z"},"trusted":true},"outputs":[],"source":["from seq2seq_transformer import EpisodicDecoder\n","\n","class AutoregressiveEpisodicAbstracter(tf.keras.Model):\n","    def __init__(self, num_layers, num_heads, dff,\n","            input_vocab_size, target_vocab_size, embedding_dim,\n","            dropout_rate=0.1, name='autoregressive_episodic_abstracter'):\n","        super().__init__(name=name)\n","        \n","        self.token_embedder = layers.Embedding(input_vocab_size, embedding_dim, name='vector_embedding')\n","        \n","        self.pos_embedding_adder_input = AddPositionalEmbedding(name='add_pos_embedding_input')\n","        self.pos_embedding_adder_target = AddPositionalEmbedding(name='add_pos_embedding_target')\n","\n","        self.encoder = Encoder(num_layers=num_layers, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate, name='encoder')\n","        self.abstracter = EpisodicDecoder(num_layers=num_layers, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate, name='abstracter')\n","        self.decoder = Decoder(num_layers=num_layers, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate, name='decoder')\n","        self.final_layer = layers.Dense(target_vocab_size, name='final_layer')\n","\n","\n","    def call(self, inputs):\n","        # To use a Keras model with `.fit` you must pass all your inputs in the\n","        # first argument.\n","        source, target  = inputs\n","        \n","        x = self.token_embedder(source)\n","        x = self.pos_embedding_adder_input(x)\n","\n","        encoder_context = self.encoder(x)\n","\n","        abstracted_context = self.abstracter(encoder_context)\n","        \n","        target_embedding = self.token_embedder(target)\n","        target_embedding = self.pos_embedding_adder_target(target_embedding)\n","\n","        x = self.decoder(target_embedding, abstracted_context)\n","\n","        # Final linear layer output.\n","        logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n","\n","        try:\n","          # Drop the keras mask, so it doesn't scale the losses/metrics.\n","          # b/250038731\n","          del logits._keras_mask\n","        except AttributeError:\n","          pass\n","\n","        # Return the final output and the attention weights.\n","        return logits"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:29:24.312995Z","iopub.status.busy":"2023-01-22T00:29:24.311532Z","iopub.status.idle":"2023-01-22T00:29:24.345851Z","shell.execute_reply":"2023-01-22T00:29:24.344765Z","shell.execute_reply.started":"2023-01-22T00:29:24.312927Z"},"trusted":true},"outputs":[],"source":["autoregressive_episodic_abstracter = AutoregressiveEpisodicAbstracter(num_layers=2, num_heads=2, dff=64, \n","    input_vocab_size=54, target_vocab_size=54, embedding_dim=128)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:29:24.348854Z","iopub.status.busy":"2023-01-22T00:29:24.348306Z","iopub.status.idle":"2023-01-22T00:29:32.361459Z","shell.execute_reply":"2023-01-22T00:29:32.360176Z","shell.execute_reply.started":"2023-01-22T00:29:24.348801Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"autoregressive_episodic_abstracter\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," vector_embedding (Embedding  multiple                 6912      \n"," )                                                               \n","                                                                 \n"," add_pos_embedding_input (Ad  multiple                 0         \n"," dPositionalEmbedding)                                           \n","                                                                 \n"," add_pos_embedding_target (A  multiple                 0         \n"," ddPositionalEmbedding)                                          \n","                                                                 \n"," encoder (Encoder)           multiple                  298112    \n","                                                                 \n"," abstracter (EpisodicDecoder  multiple                 563712    \n"," )                                                               \n","                                                                 \n"," decoder (Decoder)           multiple                  562560    \n","                                                                 \n"," final_layer (Dense)         multiple                  6966      \n","                                                                 \n","=================================================================\n","Total params: 1,438,262\n","Trainable params: 1,438,262\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["from seq2seq_transformer import masked_loss, masked_accuracy, CustomSchedule\n","\n","learning_rate = CustomSchedule(d_model=128)\n","autoregressive_episodic_abstracter.compile(\n","    loss=masked_loss, optimizer=tf.keras.optimizers.Adam(learning_rate), metrics=masked_accuracy)\n","autoregressive_episodic_abstracter((source_train, target_train))\n","\n","autoregressive_episodic_abstracter.summary()"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:29:32.363952Z","iopub.status.busy":"2023-01-22T00:29:32.363029Z","iopub.status.idle":"2023-01-22T00:32:43.435679Z","shell.execute_reply":"2023-01-22T00:32:43.434442Z","shell.execute_reply.started":"2023-01-22T00:29:32.363914Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","118/118 [==============================] - 37s 151ms/step - loss: 4.2157 - masked_accuracy: 0.0721\n","Epoch 2/10\n","118/118 [==============================] - 19s 161ms/step - loss: 3.4156 - masked_accuracy: 0.1566\n","Epoch 3/10\n","118/118 [==============================] - 17s 144ms/step - loss: 2.8791 - masked_accuracy: 0.1937\n","Epoch 4/10\n","118/118 [==============================] - 17s 143ms/step - loss: 2.5927 - masked_accuracy: 0.2199\n","Epoch 5/10\n","118/118 [==============================] - 17s 143ms/step - loss: 2.3553 - masked_accuracy: 0.2689\n","Epoch 6/10\n","118/118 [==============================] - 17s 144ms/step - loss: 1.9052 - masked_accuracy: 0.3974\n","Epoch 7/10\n","118/118 [==============================] - 16s 139ms/step - loss: 1.2085 - masked_accuracy: 0.6482\n","Epoch 8/10\n","118/118 [==============================] - 17s 142ms/step - loss: 0.6991 - masked_accuracy: 0.8147\n","Epoch 9/10\n","118/118 [==============================] - 17s 143ms/step - loss: 0.4867 - masked_accuracy: 0.8720\n","Epoch 10/10\n","118/118 [==============================] - 17s 146ms/step - loss: 0.3612 - masked_accuracy: 0.9050\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7ff08d17bc50>"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["autoregressive_episodic_abstracter.fit((source_train, target_train), labels_train,\n","    epochs=10, batch_size=64, verbose=1)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-01-22T00:32:43.438498Z","iopub.status.busy":"2023-01-22T00:32:43.437158Z","iopub.status.idle":"2023-01-22T00:32:54.981523Z","shell.execute_reply":"2023-01-22T00:32:54.980144Z","shell.execute_reply.started":"2023-01-22T00:32:43.438452Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["per-card accuracy: 91.11%\n"]}],"source":["evaluate_seq2seq_model(autoregressive_episodic_abstracter);"]},{"cell_type":"markdown","metadata":{},"source":["## Multi-Abstracter Model\n","\n","$$\\text{Encoder} \\to \\text{Abstracter} \\to \\cdots \\to \\text{Abstracter} \\to \\text{Decoder}$$\n","\n","..."]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.10 64-bit ('relml')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"feb2622714ee4f3cfc5c273fa3fe6cf9410db521c7e03d7e619a7b4bef5cf3da"}}},"nbformat":4,"nbformat_minor":4}
